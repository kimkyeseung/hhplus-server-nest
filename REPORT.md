# Redis를 이용한 성능 개선 보고서

## 1. 개요

본 보고서는 조회가 오래 걸리는 쿼리에 대한 캐싱 적용 및 Redis를 활용한 로직 이관을 통해 성능을 개선할 수 있는 방법을 분석하고, 이를 합리적인 이유와 함께 정리한 자료입니다.

## 2. 캐시란 무엇인가?

### 2.1 캐시(Cache) 정의

캐시는 **자주 사용되는 데이터를 빠르게 접근할 수 있도록 저장하는 임시 저장소**입니다. 캐싱을 활용하면 **데이터베이스나 원격 API 호출 없이 즉시 데이터를 반환**할 수 있어 성능을 크게 향상시킬 수 있습니다.

### 2.2 캐시 활용 목적

- **조회 성능 향상**: DB나 원격 서버를 거치지 않고 데이터를 반환
- **서버 부하 감소**: 반복적인 요청을 줄여 시스템 리소스를 절약
- **비용 절감**: 데이터베이스 쿼리나 API 호출 횟수를 줄여 비용 절감
- **확장성 증가**: 빠른 응답을 제공하여 트래픽 급증 상황에서도 안정적인 서비스 제공

## 3. 성능 문제 분석

### 3.1 조회가 오래 걸리는 쿼리 식별

현재 시스템에서 다음과 같은 문제점이 발견되었습니다:

- **DB에 반복적으로 실행되는 동일한 조회 쿼리**
- **대량의 데이터를 조회하는 쿼리로 인해 응답 시간이 지연됨**
- **트래픽이 많아질수록 데이터베이스 부하가 증가하여 성능 저하**

### 3.2 기존 로직의 한계

- 모든 요청이 DB에 직접 접근하여 데이터 조회
- 데이터 변경이 빈번하지 않음에도 불구하고 반복 조회 발생
- 동시 요청이 많을 경우, 쿼리 실행 시간이 길어짐

## 4. 캐시 전략 4가지

### 4.1 Read-Through 캐싱

- 캐시에 데이터가 없을 경우, 자동으로 데이터베이스에서 데이터를 가져와 캐시에 저장 후 반환
- **사용 예시**: 자주 변경되지 않는 설정값, 카테고리 정보

### 4.2 Write-Through 캐싱

- 데이터를 DB에 저장하는 동시에 캐시에도 업데이트
- **사용 예시**: 사용자 프로필 정보 (읽기와 쓰기가 빈번한 경우)

### 4.3 Write-Behind (Lazy-Write) 캐싱

- DB에 즉시 쓰지 않고 캐시에 먼저 저장 후, 일정 주기마다 배치 작업으로 DB에 반영
- **사용 예시**: 로그 저장, 대량 데이터 처리 (즉시 데이터 정합성이 중요하지 않은 경우)

### 4.4 Cache-Aside (Lazy-Loading) 캐싱

- 애플리케이션이 먼저 캐시를 조회하고 없으면 DB에서 데이터를 가져와 캐시에 저장
- **사용 예시**: 게시글 조회, 인기 상품 목록 (변경이 적고 자주 조회되는 데이터)

## 5. Redis를 이용한 로직 이관

### 5.1 대기열 로직 개선

기존 대기열은 DB 기반으로 관리되어 다음과 같은 문제가 있었습니다:

- 새로운 사용자가 대기열에 추가될 때마다 INSERT 발생
- 대기열 상태를 조회할 때마다 SELECT 쿼리 발생
- 대량의 트래픽이 발생하면 DB 부하 증가

### 5.2 Redis 기반 개선

- **ZSET (Sorted Set)을 활용하여 대기열 관리**
- 사용자를 대기열에 추가할 때 `ZADD queue_name timestamp user_id` 사용
- 대기열 상태 조회 시 `ZRANK`로 사용자의 순번을 빠르게 확인
- 활성화된 사용자는 `ZREM`을 통해 제거

#### 5.2.1 적용 예시 (TypeScript / NestJS)

```typescript
async addToQueue(userId: number): Promise<void> {
  const timestamp = Date.now();
  await this.redisClient.zAdd('user_queue', [{ score: timestamp, value: userId.toString() }]);
}

async getQueuePosition(userId: number): Promise<number | null> {
  const position = await this.redisClient.zRank('user_queue', userId.toString());
  return position !== null ? position + 1 : null;
}
```

## 6. 캐시 스탬피드(Cache Stampede) 문제

### 6.1 문제 개요

- 많은 사용자가 동시에 캐시가 만료된 데이터를 요청할 경우, 동일한 데이터에 대한 DB 조회가 동시에 발생하여 **서버 부하가 급증**하는 현상

### 6.2 해결 방법

1. **캐시 만료 시 분산 갱신 적용**
   - 캐시 TTL을 랜덤한 시간으로 설정하여 동시에 갱신되지 않도록 방지
2. **Mutex Lock을 활용한 단일 갱신**
   - 한 사용자가 데이터 갱신을 수행하는 동안 다른 사용자는 기존 데이터를 사용하도록 유도
3. **Background Refresh (백그라운드 갱신)**
   - 캐시가 만료되기 전에 별도의 작업 스레드가 데이터를 미리 갱신

## 7. 기대 효과

| 개선 항목      | 기존 DB 기반 방식        | Redis 기반 방식 |
| -------------- | ------------------------ | --------------- |
| 조회 속도      | 수십~수백 ms             | 수 ms           |
| 서버 부하      | 트래픽 증가 시 부하 급증 | 부하 최소화     |
| 동시 요청 처리 | 병목 발생 가능           | 확장성 우수     |

### 7.1 캐싱 적용 효과

- DB 부하 감소: 동일한 쿼리 반복 실행 방지
- 응답 속도 향상: 캐시된 데이터 즉시 반환 가능
- 비용 절감: 데이터베이스 쿼리 부담 감소로 인프라 비용 절감

### 7.2 Redis 기반 대기열 개선 효과

- 대기열 조회 속도 향상 (ZRANK 활용)
- 동시성 문제 해결 (Redis는 단일 스레드 처리, Race Condition 최소화)
- 확장성 증가 (Redis 클러스터링 활용 가능)

## 8. 결론

조회가 오래 걸리는 쿼리에 대해 Redis 기반 캐싱을 적용하고, 기존 DB 기반의 대기열 로직을 Redis로 이관함으로써 성능을 크게 개선할 수 있습니다. 이를 통해 **응답 속도를 향상시키고, 서버 부하를 줄이며, 확장성을 확보할 수 있습니다**. 향후 추가적인 성능 최적화를 위해 **Redis TTL 설정 및 캐싱 전략 세분화**도 고려할 수 있습니다.
